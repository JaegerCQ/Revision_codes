{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.cpp_extension import load\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import scipy.sparse as sp\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "differentiable_rapid_raditor = load(\n",
    "    name=\"differentiable_rapid_raditor\",\n",
    "    sources=[\"utils/differentiable_rapid_raditor_kernel.cpp\", \"utils/differentiable_rapid_raditor_kernel_v4_fine.cu\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom Autograd Function\n",
    "class SimulateFunction(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, sensor_location, source_location, source_p0, source_dx, dt, num_sensors, num_sources, num_times):\n",
    "        # Call the C++ forward function\n",
    "        simulate_record = differentiable_rapid_raditor.simulate(\n",
    "            sensor_location, source_location, source_p0, source_dx, dt, num_sensors, num_sources, num_times)\n",
    "        \n",
    "        # Save inputs for backward\n",
    "        ctx.save_for_backward(sensor_location, source_location, source_p0, source_dx)\n",
    "        ctx.dt = dt\n",
    "        ctx.num_sensors = num_sensors\n",
    "        ctx.num_sources = num_sources\n",
    "        ctx.num_times = num_times\n",
    "        \n",
    "        return simulate_record  # simulate_record：torch.Size([num_sensors * num_times])\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, dL_dsimulate_record):\n",
    "        # dL_dsimulate_record：torch.Size([num_sensors * num_times])\n",
    "        sensor_location, source_location, source_p0, source_dx = ctx.saved_tensors\n",
    "        dt = ctx.dt\n",
    "        num_sensors = ctx.num_sensors\n",
    "        num_sources = ctx.num_sources\n",
    "        num_times = ctx.num_times\n",
    "\n",
    "\n",
    "        # Call the C++ backward function\n",
    "        grad_source_location, grad_source_p0, grad_source_dx = differentiable_rapid_raditor.simulate_backward(\n",
    "            sensor_location, source_location, source_p0, source_dx, dL_dsimulate_record.contiguous(), dt, num_sensors, num_sources, num_times\n",
    "        )\n",
    "        return None, grad_source_location, grad_source_p0, grad_source_dx, None, None, None, None\n",
    "\n",
    "# Utility function to use the custom autograd function\n",
    "def simulate(sensor_location, source_location, source_p0, source_dx, dt, num_sensors, num_sources, num_times):\n",
    "    return SimulateFunction.apply(sensor_location, source_location, source_p0, source_dx, dt, num_sensors, num_sources, num_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Function\n",
    "# from utils.dataset_loader_full_angle import calculate_detector_location, read_one_dat_into_a_matrix\n",
    "from utils.loss_utils import l2_loss, ssim\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from utils.sliding_ball_model_for_e6_cuda0 import SlidingBallModel  \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "def load_point_cloud(file_path):\n",
    "    balls = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        start = False\n",
    "        for line in lines:\n",
    "            if start:\n",
    "                data = line.split()\n",
    "                if len(data) == 5:\n",
    "                    xyz = torch.tensor([float(data[0]), float(data[1]), float(data[2])], requires_grad=True, dtype=torch.float32, device=device)\n",
    "                    pressure_0 = torch.tensor(float(data[3]), requires_grad=True, dtype=torch.float32, device=device)\n",
    "                    radius = torch.tensor(np.log(np.exp(float(data[4]))-1), requires_grad=True, dtype=torch.float32, device=device)\n",
    "                    ball = SlidingBallModel(xyz, pressure_0, radius)\n",
    "                    balls.append(ball)\n",
    "            if 'end_header' in line:\n",
    "                start = True\n",
    "    return balls\n",
    "\n",
    "file_path = 'iteration_point_cloud_fine_recon/ball_120_after.ply'\n",
    "balls = load_point_cloud(file_path)\n",
    "print(f\"{len(balls)} balls loaded from point cloud file.\")\n",
    "\n",
    "# 随机初始化球分布\n",
    "def generate_random_balls(num_balls, boundaries, res):\n",
    "    balls = []\n",
    "    x_min, x_max, y_min, y_max, z_min, z_max = boundaries\n",
    "    for _ in range(num_balls):\n",
    "        xyz = torch.tensor([random.uniform(x_min, x_max), random.uniform(y_min, y_max), random.uniform(z_min, z_max)], requires_grad=False, dtype=torch.float32, device=device)\n",
    "        pressure_0 = torch.tensor(random.uniform(20, 100), requires_grad=True, dtype=torch.float32, device=device)\n",
    "        radius = torch.tensor(random.uniform(1*res, 6*res), requires_grad=True, dtype=torch.float32, device=device)\n",
    "        ball = SlidingBallModel(xyz, pressure_0, radius)\n",
    "        balls.append(ball)\n",
    "    return balls\n",
    "\n",
    "# 迭代函数\n",
    "def run_iterations(balls, pressure_threshold, radius_max_threshold, radius_min_threshold, boundaries):\n",
    "    new_balls = []\n",
    "    for ball in balls:\n",
    "        new_ball = ball.adaptive_density_optimization(pressure_threshold, radius_max_threshold, radius_min_threshold, boundaries)\n",
    "        if new_ball is not None:\n",
    "            new_balls.append(new_ball)\n",
    "    balls = [ball for ball in balls if not ball._is_destroyed] + new_balls\n",
    "    return balls\n",
    "\n",
    "# 保存点云数据函数\n",
    "def save_point_cloud(balls, filename):\n",
    "    points = []\n",
    "    for ball in balls:\n",
    "        if not ball._is_destroyed:\n",
    "            xyz = ball._xyz.detach().cpu().numpy()  # 转为 numpy 数组\n",
    "            pressure_0 = ball._pressure_0.item()  # 提取标量值\n",
    "            radius = ball._radius.item()  # 提取标量值\n",
    "            points.append([xyz[0], xyz[1], xyz[2], pressure_0, radius])\n",
    "\n",
    "    with open(filename, \"w\") as ply_file:\n",
    "        # 写 PLY 文件头\n",
    "        ply_file.write(\"ply\\n\")\n",
    "        ply_file.write(\"format ascii 1.0\\n\")\n",
    "        ply_file.write(f\"element vertex {len(points)}\\n\")\n",
    "        ply_file.write(\"property float x\\n\")\n",
    "        ply_file.write(\"property float y\\n\")\n",
    "        ply_file.write(\"property float z\\n\")\n",
    "        ply_file.write(\"property float pressure_0\\n\")\n",
    "        ply_file.write(\"property float radius\\n\")\n",
    "        ply_file.write(\"end_header\\n\")\n",
    "        \n",
    "        # 写入每个点的信息\n",
    "        for point in points:\n",
    "            ply_file.write(f\"{point[0]} {point[1]} {point[2]} {point[3]} {point[4]}\\n\")\n",
    "\n",
    "# 参数设置\n",
    "num_times = 4096\n",
    "Nt = num_times\n",
    "res = 0.10e-3\n",
    "Vs = 1500.0\n",
    "dt = 25e-9  # [s]\n",
    "folder_name = \"iteration_point_cloud_fine_recon_softplus\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "boundaries = (-6.4e-3, 6.4e-3, -6.4e-3, 6.4e-3, -6.4e-3, 6.4e-3)\n",
    "\n",
    "# 进行初始化，并提取初始化声源的信息\n",
    "source_num = len(balls)\n",
    "\n",
    "pressure_threshold = 15.0\n",
    "radius_max_threshold = np.log(np.exp(3 * res)-1)\n",
    "radius_min_threshold = np.log(np.exp(0.5 * res)-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取sensor_data_matrix.txt文件\n",
    "sensor_data_matrix = np.loadtxt('data/simulation_frame_01.txt', delimiter='\\t')\n",
    "real_signal = sensor_data_matrix\n",
    "real_signal = real_signal[::4, :]\n",
    "sensor_location = np.loadtxt('data/sensor_location_Sphere2048_Fibonacci.txt', delimiter='\\t')\n",
    "sensor_location = sensor_location[::4, :]\n",
    "sensor_location = sensor_location*1e-3\n",
    "sensor_num = sensor_location.shape[0]\n",
    "print(real_signal.shape)\n",
    "print(sensor_location.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 将数据转为PyTorch张量，并移动到GPU\n",
    "sensor_location = torch.tensor(sensor_location,dtype=torch.float, device=device)\n",
    "real_signal = torch.tensor(real_signal,dtype=torch.float)\n",
    "real_signal_flat = real_signal.flatten()\n",
    "real_signal_flat = real_signal_flat.to(device)\n",
    "\n",
    "# 将所有参数按照不同学习率进行分组\n",
    "def get_optim_params(balls):\n",
    "    params_xyz = [ball._xyz for ball in balls]\n",
    "    params_pressure = [ball._pressure_0 for ball in balls]\n",
    "    params_radius = [ball._radius for ball in balls]\n",
    "    return [\n",
    "        {'params': params_xyz, 'lr': 0.000003},\n",
    "        {'params': params_pressure, 'lr': 0.003},\n",
    "        {'params': params_radius, 'lr': 0.03},\n",
    "    ]\n",
    "\n",
    "optimizer = optim.Adam(get_optim_params(balls), betas=(0.9, 0.999))\n",
    "\n",
    "# 设置学习率调度器\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "num_iterations = 1000\n",
    "\n",
    "\n",
    "def build_laplacian_matrix(points, k_neighbors=10):\n",
    "    \"\"\"\n",
    "    points: torch.Tensor, shape [N, 3] (所有球的xyz坐标)\n",
    "    k_neighbors: 每个点的邻域数\n",
    "    \"\"\"\n",
    "    N = points.shape[0]\n",
    "    points_np = points.detach().cpu().numpy()  # 转为CPU numpy以加速KNN计算\n",
    "    \n",
    "    # 使用KDTree找K近邻\n",
    "    tree = KDTree(points_np)\n",
    "    distances, indices = tree.query(points_np, k=k_neighbors + 1)  # 包含自身\n",
    "    \n",
    "    # 构建稀疏权重矩阵W (高斯权重)\n",
    "    rows = np.repeat(np.arange(N), k_neighbors)\n",
    "    cols = indices[:, 1:].flatten()  # 排除自身\n",
    "    weights = np.exp(-distances[:, 1:].flatten() ** 2 / (2 * 0.1))  # 0.1为带宽参数\n",
    "    \n",
    "    # 构造稀疏矩阵（CSR格式）\n",
    "    W = sp.csr_matrix((weights, (rows, cols)), shape=(N, N))\n",
    "    D = sp.diags(W.sum(axis=1).A1)\n",
    "    L = D - W  # 拉普拉斯矩阵\n",
    "    \n",
    "    # 转换为COO格式以获取row和col属性\n",
    "    L_coo = L.tocoo()\n",
    "    \n",
    "    # 转为PyTorch稀疏张量并移到GPU\n",
    "    indices = torch.tensor(np.vstack([L_coo.row, L_coo.col]), dtype=torch.long, device=device)\n",
    "    values = torch.tensor(L_coo.data, dtype=torch.float32, device=device)\n",
    "    L_sparse = torch.sparse_coo_tensor(indices, values, size=L_coo.shape, device=device)\n",
    "    \n",
    "    return L_sparse\n",
    "# 在训练循环前定义拉普拉斯参数\n",
    "lambda_reg = 0.5  # 正则化强度\n",
    "k_neighbors = 16     # 邻域数\n",
    "\n",
    "\n",
    "# 开始迭代训练\n",
    "for iter in range(num_iterations):\n",
    "    start_time = time.time()  # 记录开始时间\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    source_location = torch.stack([ball._xyz for ball in balls])\n",
    "    # 构建拉普拉斯矩阵（仅在点云结构变化时更新）\n",
    "    if iter % 10 == 0 or iter == 0:\n",
    "        L = build_laplacian_matrix(source_location, k_neighbors)\n",
    "    \n",
    "    # 计算拉普拉斯正则项\n",
    "    laplacian_loss = torch.sum((L @ source_location) ** 2)\n",
    "\n",
    "    # 使用当前球的参数传递给simulate函数\n",
    "    source_location = torch.stack([ball._xyz for ball in balls]).flatten()\n",
    "    source_p0 = torch.stack([ball._pressure_0 for ball in balls]).flatten()\n",
    "    radius_0 = torch.stack([ball._radius for ball in balls]).flatten()\n",
    "    radius_0 = F.softplus(radius_0)\n",
    "\n",
    "    simulate_record = simulate(sensor_location, source_location, source_p0, radius_0, dt, sensor_num, source_num, num_times)  \n",
    "    data_loss = l2_loss(simulate_record, real_signal_flat)\n",
    "    \n",
    "    # 总损失\n",
    "    total_loss = data_loss + lambda_reg * laplacian_loss\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # print(f\"迭代 {iter + 1}，损失: {loss.item()}\")\n",
    "    end_time = time.time()  # 记录结束时间\n",
    "    iteration_time = end_time - start_time  # 计算时间差\n",
    "    print(f\"迭代 {iter + 1}，损失: {total_loss.item()}，时间: {iteration_time}\")\n",
    "    # 更新每个球的参数，以确保它们在相应的实例中\n",
    "    for ball in balls:\n",
    "        ball._xyz.data = ball._xyz.data.requires_grad_(True)\n",
    "        ball._pressure_0.data = ball._pressure_0.data.requires_grad_(True)\n",
    "        ball._radius.data = ball._radius.data.requires_grad_(True)\n",
    "\n",
    "    # 每10次迭代前保存点云数据到文件\n",
    "    if (iter + 1) % 10 == 0:\n",
    "        filename = f\"ball_{iter + 1}_before.ply\"\n",
    "        full_path = os.path.join(folder_name, filename)\n",
    "        save_point_cloud(balls, full_path)\n",
    "        print(f\"Point cloud saved to {filename}\")\n",
    "\n",
    "    # 每10次迭代后保存点云数据到文件\n",
    "    if (iter + 1) % 10 == 0:\n",
    "        filename = f\"ball_{iter + 1}_after.ply\"\n",
    "        full_path = os.path.join(folder_name, filename)\n",
    "        save_point_cloud(balls, full_path)\n",
    "        print(f\"Point cloud saved to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3Dgs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
